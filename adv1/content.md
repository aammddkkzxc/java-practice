- 스레드의 start() 메서드는 스레드에 스택 공간을 할당하면서 스레드를 시작하는 아주 특별한 메서드
- 쓰레드의 상태
  - New, Runnable, Blocked, Waiting, Timed Waiting, Terminated
- Runnable 인터페이스의 run() 메서드는 아무런 체크 예외를 던지지 않는다. 따라서 Runnable 인터페이스의 run() 메서드를 재정의 하는 곳에서는 체크 예외를 밖으로 던질 수 없다.
- 한 스레드가 다른 스레드의 작업이 완료될 때 까지 기다리게 하려면 -> join()
- 특정 스레드의 인스턴스에 interrupt() 메서드를 호출하면, 해당 스레드에 인터럽트가 발생 -> 대기 상태에서 깨어나 RUNNABLE 상태가 된다
  - interrupt() 를 호출했다고 해서 즉각 InterruptedException 이 발생하는 것은 아니다. 
  - 오직 sleep() 처럼 InterruptedException 을 던지는 메서드를 호출 하거나 또는 호출 중일 때 예외가 발생한다.
  - InterruptedException이 발생하면 인터럽트 상태(interrupted status)는 false로 초기화(리셋)된다.
  - 인터럽트의 목적을 달성하면 인터럽트 상태를 다시 false으로 돌려두는 것을 통해, 한번의 인터럽트로 스레드의 특정 작업 도중 중단할 수 있도록 함과 동시에, 원하지 않는 때 (예 자원 정리 중)에 인터럽트 예외가 발생하지 않도록 한다
    - interrupted() 사용 (상태확인 후 인터럽트 상태라면 true반환, 상태 false로 변경)
    - inInterrupted() -> 단순 확인
- 스레드가 RUNNABLE 상태일 때, 운영체제의 스케줄링은 다음과 같은 상태들을 가질 수 있다. 
  - 실행 상태(Running): 스레드가 CPU에서 실제로 실행 중
  - 실행 대기 상태(Ready): 스레드가 실행될 준비가 되었지만, CPU가 바빠서 스케줄링 큐에서 대기 중
  - 운영체제는 실행 상태의 스레드들을 잠깐만 실행하고 실행 대기 상태로 만든다. 그리고 실행 대기 상태의 스레드들을 잠깐만 실행 상태로 변경해서 실행한다. 이 과정을 계속 반복한다. 참고로 자바에서는 두 상태를 구분할 수는 없다.
  - yield()의 작동 
    - Thread.yield() 메서드는 현재 실행 중인 스레드가 자발적으로 CPU를 양보하여 다른 스레드가 실행될 수 있도록 한다. 
    - yield() 메서드를 호출한 스레드는 RUNNABLE 상태를 유지하면서 CPU를 양보한다. 즉, 이 스레드는 다시 스케줄링 큐에 들어가면서 다른 스레드에게 CPU 사용 기회를 넘긴다.
    - 자바에서 Thread.yield() 메서드를 호출하면 현재 실행 중인 스레드가 CPU를 양보하도록 힌트를 준다. 이는 스레드가 자신에게 할당된 실행 시간을 포기하고 다른 스레드에게 실행 기회를 주도록 한다. 
    - 참고로 yield() 는 운영체제 의 스케줄러에게 단지 힌트를 제공할 뿐, 강제적인 실행 순서를 지정하지 않는다. 그리고 반드시 다른 스레드가 실행되는 것도 아니다
    - 참고 : 10코어 이상의 CPU도 많기 때문에 스레드 10개 정도만 만들어서 실행하면, 양보가 크게 의미가 없다. 양보해도 CPU 코어가 남기 때문에 양보하지 않고 계속 수행될 수 있다. CPU 코어 수 이상의 스레드를 만들어야 양보하는 상황을 확인할 수 있다
- happens-before
  - happens-before 관계는 자바 메모리 모델에서 스레드 간의 작업 순서를 정의하는 개념
  - 한 스레드에서 수행한 작업을 다른 스레드가 참조할 때 최신 상태가 보장되는 것, 스레드 간의 메모리 가시성을 보장하는 규칙
- 메모리 가시성, volatile
  - 멀티스레드 환경에서 한 스레드가 변경한 값이 다른 스레드에서 언제 보이는지에 대한 문제를 메모리 가시성 (memory visibility)이라 한다.
  - 주로 컨텍스트 스위칭이 될 때, 캐시 메모리도 함께 갱신되는데, 이 부분도 환경에 따라 달라질 수 있다.
  - volatile 을 적용하면 캐시 메모리가 아니라 메인 메모리에 항상 직접 접근하기 때문에 성능이 상대적으로 떨어진다
- 메모리 가시성 문제와 동시성 문제는 다르다
  - 한 스레드에서 synchronized 블록을 종료한 후, 그 모니터 락을 얻는 모든 스레드는 해당 블록 내의 모든 작업을 볼 수 있다. 예를 들어, synchronized(lock) { ... } 블록 내에서의 작업은 블록을 나가는 시점에 happensbefore 관계가 형성된다
  - synchronized를 사용하면 volatile 를 사용하지 않아도 메모리 가시성 문제가 해결된다
- 지역 변수, 불변 객체의 경우 멀티 스레드 문제에서 안전한 이유를 생각해보자
- 동기화 / 고급 동기화
  - Lock, ReentrantLock -> synchronized 단점 (무한대기, 공정성 문제) 해결
    - 무한대기 
      - 모니터 락과 BLOCKED 상태는 synchronized 에서만 사용된다.
      - BLOCKED 상태의 스레드는 락이 풀릴 때 까지 무한 대기 -> 인터럽트로도 대기 상태를 깨어나지 못함
    - 공정성
      -  락이 돌아왔을 때 BLOCKED 상태의 여러 스레드 중에 어떤 스레드가 락을 획득할 지 알 수 없다
    - ReentrantLock
      - 여기서 사용하는 락은 객체 내부에 있는 모니터 락이 아니다 Lock 인터페이스와 ReentrantLock 이 제공하는 기능
      - 다양한 메서드 제공해서 세밀한 제어 가능
- 생산자 / 소비자 문제
  - synchronized Object.wait, notify, notifyAll
    -  무한 대기 문제, 스레드 기아 문제 해결 가능하나 비효율은 여전히 존재 (생산자가 생산자를 깨우고, 소비자가 소비자를 깨우는 비효율)
  - Lock, ReentrantLock 사용, 별도의 대기공간 Condition사용 (모든 객체 인스턴스가 내부에 기본으로 가지는 스레드 대기공간 아님, 생산자 / 소비자 대기공간 나누기)
  - synchronized 와 마찬가지로 ReentrantLock 도 대기소가 2단계로 되어 있다 (락 대기 공간, 스레드 대기 공간)
    - 원리는 비슷하나, 락 대기 공간에서 BLOCKED 상태로 대기한다는 것과 스레드 대기공간의 구분에서 차이가 있음
  - 잘 설계된 java.util.concurrent.BlockingQueue 라는 특별한 멀티스레드 자료 구조 사용하면 된다 (큐가 가득 찼을 때 생각할 수 있는 선택지는 4가지 전부 커버)
- CAS 연산
  - 원자적인 연산은 스레드 입장에서 쪼갤 수 없는 하나의 연산. 따라서 여러 스레드가 동시에 실행해도 안전.
  - 안전한 임계 영역이 필요하지만, 충돌 가능성이 낮고, 아주 간단한 연산일 때 사용할 수 있다
  - 여러 스레드에서 발생하는 주문 수를 실시간으로 증가하면서 카운트 하는 경우 사용해 볼 수 있음
  - 데이터베이스의 결과를 대기한다거나, 다른 서버의 요청을 기다린다거나 하는 것 처럼 오래 기다리는 작업에 사용하면 CPU를 계속 사용하며 기다리는 최악의 결과
  - 아주 가벼운 락도 구현 가능하다. 다만 RUNNABLE 상태로 락을 획득할 때 까지 while문을 반복하는 문제가 있다 (스핀 대기)
  - 사실 직접 사용할 일은 거의 없다.
- 동시성 컬렉션
  - Collections.synchronizedXxx(target) 으로 프록시 패턴 사용한 동시성 컬렉션 만들 수 있지만, 최적화 안되어 있다. 되도록 자바에서 제공하는 컬렉션 사용하는 것이 좋음
  - LinkedHashSet , LinkedHashMap 처럼 입력 순서를 유지하는 동시에 멀티스레드 환경에서 사용할 수 있는 Set , Map 구현체는 제공하지 않는다. 위 방법 사용해야 함
- Executor 프레임워크 / 스레드 풀이 필요한 이유??
  - 스레드 생성 비용으로 인한 성능 문제
    - 메모리 할당 (호출 스택)
    - 운영체제 자원 사용 (시스템 콜)
    - 운영체제 스케줄러 설정
  - 스레드 관리 문제
    - 자원이 한정되어 있다 -> 몇개 만들지
    - 애플리 케이션이 종료될 때 실행 중인 스레드를 어떻게 관리할 것인지
- Callable
  - 반환타입 제네릭, 메서드가 Exception을 던짐 -> Runnable 처럼 구현 메서드 내부에서 처리할 필요가 없다
- Future
  - Callable 작업을 처리하는 스레드 풀의 스레드가 작업을 완료 한 상태 or 완료하지 않은 상태 일 수 있다 (언제 실행이 완료되어서 결과를 반환할 지 알 수 없음)
  - 요청 스레드는 Future를 즉시 반환하기 때문에 대기하지 않아도 됨 -> 요청 스레드가 future.get() 을 호출하면 Future 가 완료 상태가 될 때 까지 대기 (블로킹)
  - 필요한 모든 요청을 한 다음에 Future.get() 을 통해 블로킹 상태로 대기하며 결과를 받을 수 있는 이점이 있다
  - 작업이 이미 실행 중인지 여부에 따라 취소 옵션 설정 가능, 작업 중 발생한 예외도 처리 가능 (작업에서 예외 발생 -> Future 의 상태가 FAILED -> ExecutionException 예외, 작업중에 발생한 예외 포함하고 있음)
- ExecutorService 우아한 종료
  - 애플리케이션이 갑자기 재시작 된다면? -> 이상적인 방향은 shutdown() 으로 새로운 주문 요청은 막고, 이미 진행중인 주문은 모두 완료한 다음에 서버를 재시작
  - 갑자기 요청이 너무 많이 들어와서 큐에 대기중인 작업이 너무 많아 작업 완료 어렵거나, 작업이 너무 오래 걸리거나, 또는 버그가 발생해서 특정 작업이 끝나지 않을 수 있다
  - 이럴 때는 보통 우아하게 종료하는 시간을 정한다. 예를 들어서 60초까지는 작업을 다 처리할 수 있게 기다리는 것. 그리고 60초가 지나면, 무언가 문제가 있다고 가정하고 shutdownNow() 를 호출해서 작업들을 강제로 종료
- Executor 스레드 풀 관리 방식
  - 쓰레드풀에 설정한 corePoolSize, maximumPoolSize, keepAliveTime이 어떻게 동작하는지 꼭 생각해보자. 쓰레드를 미리 생성하려면 어떻게 해야 하는지도
- Executor 스레드 풀 관리 전략
  - 고정 풀 전략
    - 고정 스레드, 큐 사이즈는 제한 X
    - 스레드 수가 고정되어서 CPU, 메모리 리소스가 어느정도 예측 가능 -> 안정적으로 운영할 수 있으나, 갑작스런 요청 증가시 서버 자원은 여유가 있는데, 사용자만 점점 느려지는 문제가 발생
  - 캐시 풀 전략
    - 작업의 요청 수에 따라서 스레드도 증가하고 감소하므로, 매우 유연하다.
    - 사용자 요청이 폭증하면, CPU 사용량이 100%이고, 너무 많은 스레드(메모리 사용량 높아짐)가 작업을 처리하면서 시스템 전체가 느려지는 현상 발생
    - 캐시 스레드 풀 전략은 서버의 자원을 최대한 사용하지만, 서버가 감당할 수 있는 임계점을 넘는 순간 시스템이 다운될 수 있다
  - 사용자 정의 풀 전략
    - 일반/긴급/거절 단계로 설정
    - 큐 사이즈를 꼭 설정하자 LinkedBlockingQueue 사용하는 실수 하지말자 (무한대 큐 사이즈를 가짐, 실무에서 발생하는 실수)
    - CPU 메모리를 사용하기 때문에 이런 부분을 감안해서 긴급상황에 투입할 스레드의 최대 개수를 정해야 한다
    - 예시 : cpu사용량을 기본으로 50% 정도로 하다가 긴급한 상황에는 80%까지 사용하도록 설정
    - 사용자에게 다시 요청하도록 하고 시스템이 다운되는 최악의 상황은 피한다.
  - 실무 전략
    - 일반적인 상황이라면 고정 스레드 풀 전략이나, 캐시 스레드 풀 전략을 사용하면 충분
    - 우리가 만든 서비스가 잘 되어서 많은 요청이 들어오면 좋겠지만, 대부분의 서비스는 트래픽이 어느정도 예측 가능
    - 많은 개발자가 미래에 발생하지 않을 일 때문에 코드를 최적화하는 경우가 많다
    - 어쩔 때는 가장 좋은 최적화는 최적화하지 않는 것이다
    - 백엔드 서버 개발자라면 시스템의 자원을 적절하게 활용하되, 또 적절한 거절을 통해 시스템이 다운되지 않도록 하는 것이 필요하다.
- Executor 예외 정책
  - ThreadPoolExecutor 는 작업을 거절하는 다양한 정책을 제공
  - AbortPolicy, DiscardPolicy, CallerRunsPolicy, 사용자 정의